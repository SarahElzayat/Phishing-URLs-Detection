{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler   \n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training and test data from csv files\n",
    "TRAINING_PATH = \"./train_selected.csv\"\n",
    "TESTING_PATH = \"./test_selected.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName(\"SVM\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length:  177041\n",
      "Testing data length:  58329\n",
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1|101480|\n",
      "|    0| 75561|\n",
      "+-----+------+\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|33370|\n",
      "|    0|24959|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_rdd = spark.read.csv(TRAINING_PATH, header=True, inferSchema=True)\n",
    "testing_rdd = spark.read.csv(TESTING_PATH, header=True, inferSchema=True)\n",
    "# print dataset length\n",
    "print(\"Training data length: \", training_rdd.count())\n",
    "print(\"Testing data length: \", testing_rdd.count())\n",
    "\n",
    "# print the count of label values in training data\n",
    "training_rdd.groupBy(\"label\").count().show()\n",
    "testing_rdd.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify the feature columns, excluding the label column\n",
    "feature_columns = [col for col in training_rdd.columns if col in [ \"URLLength\", \"URLSimilarityIndex\"]]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Assemble features for both train and test datasets\n",
    "train_df = assembler.transform(training_rdd).select(\"features\", \"label\")\n",
    "test_df = assembler.transform(testing_rdd).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LinearSVC model\n",
    "svm = LinearSVC(labelCol=\"label\", featuresCol=\"features\", maxIter=100)\n",
    "\n",
    "# Train the LinearSVC model\n",
    "svm_model = svm.fit(train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svm_model.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.995667670200688\n"
     ]
    }
   ],
   "source": [
    "# training accuracy\n",
    "training_pred = svm_model.transform(train_df)\n",
    "training_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\").evaluate(training_pred)\n",
    "print(\"Training accuracy: \", training_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|       0.0|24691|\n",
      "|       1.0|33638|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.9954\n",
      "Test Precision = 0.9954\n",
      "Test Recall = 0.9954\n",
      "Test F1 Score = 0.9954\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    0|       0.0|24691|\n",
      "|    1|       1.0|33370|\n",
      "|    0|       1.0|  268|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model using accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test Accuracy = {accuracy:.4f}\")\n",
    "\n",
    "# Evaluate the model using additional metrics\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "print(f\"Test Precision = {precision:.4f}\")\n",
    "\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "print(f\"Test Recall = {recall:.4f}\")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_evaluator.evaluate(predictions)\n",
    "print(f\"Test F1 Score = {f1:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "predictions.groupBy(\"label\", \"prediction\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
